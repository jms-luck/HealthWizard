{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhanu\\.conda\\envs\\bt\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 2\n",
      "Python-dotenv could not parse statement starting at line 3\n",
      "Python-dotenv could not parse statement starting at line 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import speech_recognition as sr\n",
    "from typing import List, Optional, Union\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from langchain.agents import AgentExecutor, AgentOutputParser, LLMSingleActionAgent, Tool\n",
    "from langchain.tools import Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from PIL import Image\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "\n",
    "# Set API keys directly\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCgaz3OFtXuNx-SCRPz2N58UCfpo0pcH_g\"\n",
    "os.environ[\"SERPER_API_KEY\"] = \"ed4acec1529a6f8755a04900d2554b5252aba850b59262e44712c7596509ef4a\"\n",
    "os.environ[\"AZURE_MAPS_KEY\"] = \"EumXcWSYqKLcsw9zymB1cPRIfDzNbZBXO7BCjKsbsAITXSpRIZbMJQQJ99BBACYeBjFPDDZUAAAgAZMP1DsH\"\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API keys are set\n",
    "required_keys = [\"TAVILY_API_KEY\", \"GOOGLE_API_KEY\", \"SERPER_API_KEY\", \"AZURE_MAPS_KEY\"]\n",
    "for key in required_keys:\n",
    "    if not os.getenv(key):\n",
    "        sys.exit(f\"Error: {key} not found in environment variables. Please set it in .env file.\")\n",
    "\n",
    "# Configure Google API\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import speech_recognition as sr\n",
    "from typing import List, Optional, Union\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from langchain.agents import AgentExecutor, AgentOutputParser, LLMSingleActionAgent, Tool\n",
    "from langchain.tools import Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from PIL import Image\n",
    "from langchain.schema import AgentAction, AgentFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhanu\\AppData\\Local\\Temp\\ipykernel_4248\\1405612540.py:235: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"input\")\n",
      "C:\\Users\\dhanu\\AppData\\Local\\Temp\\ipykernel_4248\\1405612540.py:219: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  agent = LLMSingleActionAgent(llm_chain=LLMChain(llm=llm, prompt=prompt), output_parser=CustomAgentOutputParser(), stop=[\"\\nObservation:\"], allowed_tools=[t.name for t in tools])\n",
      "C:\\Users\\dhanu\\AppData\\Local\\Temp\\ipykernel_4248\\1405612540.py:219: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = LLMSingleActionAgent(llm_chain=LLMChain(llm=llm, prompt=prompt), output_parser=CustomAgentOutputParser(), stop=[\"\\nObservation:\"], allowed_tools=[t.name for t in tools])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Medical Assistant ===\n",
      "Please specify your preferred language (e.g., English, Spanish, French).\n",
      "Language set to ta\n",
      "Please provide the English medical text you want me to translate to Tamil.  I need the text to be able to translate it.  I can't offer translation without the input text.\n",
      "\n",
      "உரையாடலை மீட்டமைக்க உரை உள்ளீட்டின் போது 'தெளிவான வரலாறு' என தட்டச்சு செய்யவும். (Uraiyaaṭại mīṭṭamaiakka urại uḷḷīṭṭin pōthu 'telivāna varaḷāṛu' ena taṭṭaccu seyyavum.)\n",
      "\n",
      "தவறான தேர்வு. 1, 2, 3 அல்லது q-ஐத் தேர்ந்தெடுக்கவும்.\n",
      "\n",
      "\n",
      "The Tamil translation of \"Assistant\" depends on the context.  Here are a few options:\n",
      "\n",
      "* **உதவியாளர் (Uthaviyāļaṛ):** This is the most common and general translation, suitable for most medical contexts.  It means \"helper\" or \"assistant.\"\n",
      "\n",
      "* **உதவி (Uthavi):** This means \"help\" or \"assistance.\"  This would be appropriate if \"assistant\" is used adjectivally, as in \"assistant physician.\"  You might say \"உதவி மருத்துவர்\" (Uthavi maruththuvar) for \"assistant physician.\"\n",
      "\n",
      "* **துணை (Thunae):** This means \"companion\" or \"aide.\"  It might be suitable depending on the specific role of the assistant.\n",
      "\n",
      "* **சகாயம் (Sakāyam):** This means \"help\" or \"aid.\"  Similar to \"உதவி,\" but can be used in a more formal setting.\n",
      "\n",
      "\n",
      "To provide the most accurate translation, please provide the full sentence or context in which \"Assistant\" is used.  For example, \"Assistant Professor,\" \"Surgical Assistant,\" \"Research Assistant\" all require slightly different translations.\n",
      " சாட் வரலாறு நீங்கள் \"சளி\" என்ற தமிழ் வார்த்தையின் பொருளில் ஆர்வம் காட்டியுள்ளீர்கள் என்பதைக் காட்டுகிறது. ஆனால், உங்களுக்கு எந்தவொரு உடல்நலப் பிரச்சனையும் இருப்பதாக அது குறிப்பிடவில்லை. உங்களுக்கு உடல்நிலை சரியில்லாமல் இருக்கிறதா?  அப்படியானால், உங்கள் அறிகுறிகள் பற்றி மேலும் கூறுங்கள். உதாரணமாக,  காசல், தொண்டை வலி, தலைவலி, காய்ச்சல் அல்லது வேறு ஏதேனும் சிரமம் உள்ளதா? உங்கள் அறிகுறிகளை அறிந்தால், என்ன நடக்கலாம் என்பதை நான் புரிந்து கொள்ள உதவும்.  பின்னர் நான் சில ஆலோசனைகளை வழங்கலாம், ஆனால் நினைவில் கொள்ளுங்கள், நான் ஒரு AI ஆகையால் நோய் கண்டறிய முடியாது.  தீவிரமான பிரச்சினைகளுக்கு ஒரு சுகாதார வழங்குநரை அணுகவும். என் ஆலோசனை வழிகாட்டுதலுக்காக மட்டுமே.\n",
      "\n",
      "The best translation of \"Goodbye\" in Tamil depends on the context.  In a medical setting, a formal farewell would be appropriate.  Therefore, the best option would be:\n",
      "\n",
      "**சந்தோஷமாக இருங்கள் (Saanthōshāgā iruṅkaḷ)** - This translates to \"Be well\" or \"Stay happy,\" which is a polite and appropriate farewell in a medical context.  It expresses well wishes for the patient's health.\n",
      "\n",
      "\n",
      "Other options, less formal and perhaps not ideal for a medical setting, include:\n",
      "\n",
      "* **போய் வாருங்கள் (Pōy vāruṅkaḷ)** -  Go, come (implying a return)\n",
      "* **நன்றி (Naṉṟi)** - Thank you (if the goodbye is following an interaction)\n",
      "\n",
      "\n",
      "But **சந்தோஷமாக இருங்கள் (Saanthōshāgā iruṅkaḷ)** is the most suitable for a medical professional to say to a patient.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify API keys are set\n",
    "required_keys = [\"TAVILY_API_KEY\", \"GOOGLE_API_KEY\", \"SERPER_API_KEY\", \"AZURE_MAPS_KEY\"]\n",
    "for key in required_keys:\n",
    "    if not os.getenv(key):\n",
    "        sys.exit(f\"Error: {key} not found in environment variables. Please set it in .env file.\")\n",
    "\n",
    "# Configure Google API\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Initialize DuckDuckGo search tool\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# System Prompts\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert medical doctor providing empathetic and structured health advice. Engage patients conversationally based on the chat history to identify their health issues (e.g., illness, aches) and offer tailored solutions, including remedies, medication suggestions (with disclaimers), diet plans, and exercises.\n",
    "\n",
    "Example:\n",
    "Patient: \"I've been having a fever.\"\n",
    "Assistant: \"How long have you had this fever?\"\n",
    "Patient: \"Three days.\"\n",
    "Assistant: \"Are you experiencing symptoms like cough or fatigue?\"\n",
    "\n",
    "When appropriate, use actions in this format:\n",
    "- \"Action: find_doctors : condition near location\"\n",
    "- \"Action: find_pharmacies : location\"\n",
    "- \"Action: analyze_medical_image : image_path\"\n",
    "\n",
    "If the patient provides a location and condition, suggest doctors immediately using the `find_doctors` action. Include disclaimers: 'Consult a healthcare provider for serious issues. I cannot diagnose your condition; my advice is for guidance only.'\n",
    "Chat history is provided below for context.\n",
    "\"\"\"\n",
    "\n",
    "DOCTOR_AGENT_PROMPT = \"\"\"\n",
    "You are a medical referral specialist. Analyze the patient's condition and location from the input and chat history to recommend appropriate specialists. Use search tools to find real doctors, providing specialty type, rationale, and contact details if available.\n",
    "\"\"\"\n",
    "\n",
    "PHARMACY_AGENT_PROMPT = \"\"\"\n",
    "You are a pharmacy specialist. Recommend over-the-counter medications, pharmacy services, and use search tools to find real pharmacies near the patient's location based on the input and chat history. Include disclaimers about prescriptions.\n",
    "\"\"\"\n",
    "\n",
    "IMAGE_ANALYSIS_PROMPT = \"\"\"\n",
    "Analyze this medical image professionally, suggesting possible conditions (e.g., skin issues like rashes or scars, injuries). Describe observations, recommend next steps, and emphasize consulting a doctor. Note: This is not a definitive diagnosis. Only process images related to medical conditions.\n",
    "\"\"\"\n",
    "\n",
    "# Azure Maps API Functions\n",
    "def get_location_coordinates(location):\n",
    "    url = \"https://atlas.microsoft.com/search/address/json\"\n",
    "    params = {\n",
    "        \"api-version\": \"1.0\",\n",
    "        \"subscription-key\": os.getenv(\"AZURE_MAPS_KEY\"),\n",
    "        \"query\": location,\n",
    "        \"limit\": 1\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data.get(\"results\") and len(data[\"results\"]) > 0:\n",
    "            position = data[\"results\"][0][\"position\"]\n",
    "            return position[\"lat\"], position[\"lon\"]\n",
    "        return None, None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Azure Maps geocoding error: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def azure_maps_search_poi(lat, lon, search_term, entity_type, radius=10000, limit=5):\n",
    "    search_url = \"https://atlas.microsoft.com/search/poi/json\"\n",
    "    if entity_type == \"doctors\":\n",
    "        search_term = f\"{search_term} doctor medical\"\n",
    "    elif entity_type == \"pharmacies\":\n",
    "        search_term = f\"pharmacy {search_term}\"\n",
    "    search_params = {\n",
    "        \"api-version\": \"1.0\",\n",
    "        \"subscription-key\": os.getenv(\"AZURE_MAPS_KEY\"),\n",
    "        \"query\": search_term,\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon,\n",
    "        \"radius\": radius,\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    try:\n",
    "        search_response = requests.get(search_url, params=search_params)\n",
    "        search_response.raise_for_status()\n",
    "        search_data = search_response.json()\n",
    "        if not search_data.get(\"results\") or len(search_data[\"results\"]) == 0:\n",
    "            return f\"No {entity_type} found for '{search_term}' near the specified location.\"\n",
    "        results = []\n",
    "        for i, result in enumerate(search_data[\"results\"], 1):\n",
    "            poi = result.get(\"poi\", {})\n",
    "            address = result.get(\"address\", {})\n",
    "            phone = poi.get(\"phone\", \"No phone number available\")\n",
    "            street = f\"{address.get('streetNumber', '')} {address.get('streetName', '')}\".strip()\n",
    "            locality = address.get('localName', '') or address.get('municipality', '')\n",
    "            region = address.get('countrySubdivision', '')\n",
    "            full_address = \", \".join(filter(None, [street, locality, region])) or \"Address not available\"\n",
    "            result_str = f\"{i}. {poi.get('name', 'Unnamed')}\\n   Address: {full_address}\\n   Phone: {phone}\\n\"\n",
    "            categories = poi.get('categories', [])\n",
    "            if categories:\n",
    "                result_str += f\"   Category: {', '.join(categories)}\\n\"\n",
    "            results.append(result_str)\n",
    "        return \"\\n\".join(results)\n",
    "    except requests.RequestException as e:\n",
    "        return f\"Azure Maps search error: {str(e)}\"\n",
    "\n",
    "def azure_maps_search(query, entity_type, limit=5):\n",
    "    parts = query.split(\"near\")\n",
    "    if len(parts) != 2:\n",
    "        return f\"Please specify a search in the format 'condition near location'.\"\n",
    "    search_term = parts[0].strip()\n",
    "    location = parts[1].strip()\n",
    "    lat, lon = get_location_coordinates(location)\n",
    "    if not lat or not lon:\n",
    "        return f\"Location '{location}' not found. Please try a different location.\"\n",
    "    return azure_maps_search_poi(lat, lon, search_term, entity_type, limit=limit)\n",
    "\n",
    "# Search Functions\n",
    "def tavily_search(query: str) -> str:\n",
    "    api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "    url = \"https://api.tavily.com/search\"\n",
    "    params = {\"api_key\": api_key, \"query\": query, \"max_results\": 5}\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        results = data.get(\"results\", [])\n",
    "        if not results:\n",
    "            return \"No results found with Tavily.\"\n",
    "        return \"\\n\".join([f\"{i}. {r.get('title', 'No title')}: {r.get('content', 'No content')[:200]}...\\n   {r.get('url', 'No URL')}\" for i, r in enumerate(results, 1)])\n",
    "    except requests.RequestException as e:\n",
    "        return f\"Tavily search error: {str(e)}\"\n",
    "\n",
    "def serper_search(query: str) -> str:\n",
    "    api_key = os.getenv(\"SERPER_API_KEY\")\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    payload = {\"q\": query, \"num\": 5}\n",
    "    headers = {\"X-API-KEY\": api_key, \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        results = data.get(\"organic\", [])\n",
    "        if not results:\n",
    "            return \"No results found with Serper.\"\n",
    "        return \"\\n\".join([f\"{i}. {r.get('title', 'No title')}: {r.get('snippet', 'No snippet')}\\n   {r.get('link', 'No link')}\" for i, r in enumerate(results, 1)])\n",
    "    except requests.RequestException as e:\n",
    "        return f\"Serper search error: {str(e)}\"\n",
    "\n",
    "def multi_search(query: str) -> str:\n",
    "    results = []\n",
    "    for func in [search_tool.run, tavily_search, serper_search]:\n",
    "        try:\n",
    "            result = func(query)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            results.append(f\"Search failed: {str(e)}\")\n",
    "    combined = \"\\n\\n\".join([f\"--- Source {i+1} ---\\n{r}\" for i, r in enumerate(results) if r])\n",
    "    if len(combined) > 2000:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        try:\n",
    "            summary = model.generate_content(f\"Summarize this search result:\\n{combined[:10000]}\").text\n",
    "            return f\"Summary:\\n{summary}\"\n",
    "        except Exception as e:\n",
    "            return f\"Summary failed: {str(e)}\\nTruncated Results:\\n{combined[:2000]}\"\n",
    "    return combined\n",
    "\n",
    "# Custom LLM for LangChain\n",
    "class GoogleGenAI(LLM):\n",
    "    model_name: str = \"gemini-1.5-flash\"\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        model = genai.GenerativeModel(self.model_name)\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"LLM error: {str(e)}\"\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"google-generativeai\"\n",
    "\n",
    "# Agent Utilities\n",
    "class CustomAgentOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            final_answer = llm_output.split(\"Final Answer:\")[-1].strip()\n",
    "            return AgentFinish(return_values={\"output\": final_answer}, log=llm_output)\n",
    "        regex = r\"Action:\\s*(\\w+)\\s*:\\s*(.+)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if match:\n",
    "            action, input_str = match.group(1).strip(), match.group(2).strip()\n",
    "            return AgentAction(tool=action, tool_input=input_str, log=llm_output)\n",
    "        return AgentFinish(return_values={\"output\": llm_output.strip()}, log=llm_output)\n",
    "\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template: str = \"\"\"\n",
    "    {agent_prompt}\n",
    "    Tools:\n",
    "    {tools}\n",
    "    Chat History:\n",
    "    {chat_history}\n",
    "    Question: {input}\n",
    "    Agent Scratchpad:\n",
    "    {agent_scratchpad}\n",
    "    \"\"\"\n",
    "    tools: List[Tool]\n",
    "    agent_prompt: str\n",
    "    def format(self, **kwargs) -> str:\n",
    "        kwargs[\"agent_prompt\"] = self.agent_prompt\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{t.name}: {t.description}\" for t in self.tools])\n",
    "        kwargs[\"chat_history\"] = kwargs.get(\"chat_history\", \"\")\n",
    "        kwargs[\"agent_scratchpad\"] = kwargs.get(\"agent_scratchpad\", \"\")\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "# Agent Setup\n",
    "def get_doctor_agent(llm: LLM, memory: ConversationBufferMemory):\n",
    "    tools = [\n",
    "        Tool(name=\"search_doctors\", func=lambda q: multi_search(f\"doctors {q}\"), description=\"Search for doctors based on a general query.\"),\n",
    "        Tool(name=\"find_doctors_nearby\", func=lambda q: azure_maps_search(q, \"doctors\"), description=\"Find doctors for a condition near a location using Azure Maps. Input format: 'condition near location'.\")\n",
    "    ]\n",
    "    prompt = CustomPromptTemplate(tools=tools, agent_prompt=DOCTOR_AGENT_PROMPT, input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"])\n",
    "    agent = LLMSingleActionAgent(llm_chain=LLMChain(llm=llm, prompt=prompt), output_parser=CustomAgentOutputParser(), stop=[\"\\nObservation:\"], allowed_tools=[t.name for t in tools])\n",
    "    return AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=False)\n",
    "\n",
    "def get_pharmacy_agent(llm: LLM, memory: ConversationBufferMemory):\n",
    "    tools = [\n",
    "        Tool(name=\"search_pharmacies\", func=lambda q: multi_search(f\"pharmacies {q}\"), description=\"Search for pharmacies based on a general query.\"),\n",
    "        Tool(name=\"find_pharmacies_nearby\", func=lambda q: azure_maps_search(q, \"pharmacies\"), description=\"Find pharmacies near a location using Azure Maps. Input format: 'service near location'.\")\n",
    "    ]\n",
    "    prompt = CustomPromptTemplate(tools=tools, agent_prompt=PHARMACY_AGENT_PROMPT, input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"])\n",
    "    agent = LLMSingleActionAgent(llm_chain=LLMChain(llm=llm, prompt=prompt), output_parser=CustomAgentOutputParser(), stop=[\"\\nObservation:\"], allowed_tools=[t.name for t in tools])\n",
    "    return AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=False)\n",
    "    \n",
    "# Medical Assistant Class\n",
    "class MedicalAssistant:\n",
    "    def __init__(self):\n",
    "        self.llm = GoogleGenAI()\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"input\")\n",
    "        self.doctor_agent = get_doctor_agent(self.llm, self.memory)\n",
    "        self.pharmacy_agent = get_pharmacy_agent(self.llm, self.memory)\n",
    "        self.actions = {\n",
    "            \"find_doctors\": self.find_doctors,\n",
    "            \"find_pharmacies\": self.find_pharmacies,\n",
    "            \"analyze_medical_image\": self.analyze_medical_image\n",
    "        }\n",
    "        self.user_lang = None\n",
    "        self.interface_texts = {}\n",
    "\n",
    "    def translate(self, text, source_lang, target_lang):\n",
    "        \"\"\"Translate text using the LLM.\"\"\"\n",
    "        if source_lang == target_lang:\n",
    "            return text\n",
    "        prompt = f\"Translate the following medical text from {source_lang} to {target_lang}: {text}\"\n",
    "        translated_text = self.llm._call(prompt)\n",
    "        if translated_text.startswith(\"LLM error\"):\n",
    "            print(translated_text)\n",
    "            return text\n",
    "        return translated_text\n",
    "\n",
    "    def find_doctors(self, query: str) -> str:\n",
    "        try:\n",
    "            azure_results = azure_maps_search(query, \"doctors\")\n",
    "            if \"error\" not in azure_results.lower() and \"not found\" not in azure_results.lower() and \"please specify\" not in azure_results.lower():\n",
    "                return f\"Found doctors using Azure Maps:\\n\\n{azure_results}\\n\\nDisclaimer: Consult a healthcare provider for professional medical advice.\"\n",
    "            result = self.doctor_agent.invoke({\"input\": query, \"chat_history\": self.memory.buffer})[\"output\"]\n",
    "            return f\"{result}\\n\\nDisclaimer: Consult a healthcare provider for professional medical advice.\"\n",
    "        except Exception as e:\n",
    "            print(f\"Doctor search error: {str(e)}\")\n",
    "            web_search_result = multi_search(f\"doctors for {query}\")\n",
    "            return f\"Could not find doctors through maps due to an error. Here are web search results:\\n\\n{web_search_result}\\n\\nDisclaimer: Consult a healthcare provider for professional medical advice.\"\n",
    "\n",
    "    def find_pharmacies(self, query: str) -> str:\n",
    "        try:\n",
    "            if \"near\" not in query.lower():\n",
    "                query = f\"pharmacies near {query}\"\n",
    "            azure_results = azure_maps_search(query, \"pharmacies\")\n",
    "            if \"error\" not in azure_results.lower() and \"not found\" not in azure_results.lower() and \"please specify\" not in azure_results.lower():\n",
    "                return f\"Found pharmacies using Azure Maps:\\n\\n{azure_results}\\n\\nDisclaimer: Consult a pharmacist or doctor before taking medications.\"\n",
    "            result = self.pharmacy_agent.invoke({\"input\": query, \"chat_history\": self.memory.buffer})[\"output\"]\n",
    "            return f\"{result}\\n\\nDisclaimer: Consult a pharmacist or doctor before taking medications.\"\n",
    "        except Exception as e:\n",
    "            print(f\"Pharmacy search error: {str(e)}\")\n",
    "            web_search_result = multi_search(f\"pharmacies in {query}\")\n",
    "            return f\"Could not find pharmacies through maps due to an error. Here are web search results:\\n\\n{web_search_result}\\n\\nDisclaimer: Consult a pharmacist or doctor before taking medications.\"\n",
    "\n",
    "    def analyze_medical_image(self, image_path: str) -> str:\n",
    "        if not os.path.isfile(image_path):\n",
    "            error_msg = \"Error: Image file not found.\"\n",
    "            return self.translate(error_msg, \"en\", self.user_lang)\n",
    "        try:\n",
    "            print(\"Uploading and analyzing medical image...\")\n",
    "            file = genai.upload_file(path=image_path, display_name=\"Medical Image\")\n",
    "            model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "            last_user_input = next((m.content for m in reversed(self.memory.chat_memory.messages) if isinstance(m, HumanMessage)), \"\")\n",
    "            prompt = IMAGE_ANALYSIS_PROMPT + (f\"\\nUser query: {last_user_input}\" if last_user_input else \"\")\n",
    "            response_en = model.generate_content([file, prompt]).text\n",
    "            response = self.translate(response_en, \"en\", self.user_lang)\n",
    "            disclaimer_en = \"Disclaimer: This is not a definitive diagnosis. Consult a doctor.\"\n",
    "            disclaimer = self.translate(disclaimer_en, \"en\", self.user_lang)\n",
    "            return f\"{response}\\n\\n{disclaimer}\"\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Image analysis error: {str(e)}\"\n",
    "            return self.translate(error_msg, \"en\", self.user_lang)\n",
    "\n",
    "    def get_voice_input(self) -> Optional[str]:\n",
    "        recognizer = sr.Recognizer()\n",
    "        language_codes = {\n",
    "            \"en\": \"en-US\",\n",
    "            \"es\": \"es-ES\",\n",
    "            \"fr\": \"fr-FR\",\n",
    "            \"de\": \"de-DE\",\n",
    "            # Add more as needed\n",
    "        }\n",
    "        language = language_codes.get(self.user_lang, \"en-US\")\n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                print(self.translate(\"Speak your health concern (10 seconds)...\", \"en\", self.user_lang))\n",
    "                recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "                audio = recognizer.listen(source, timeout=10, phrase_time_limit=10)\n",
    "            return recognizer.recognize_google(audio, language=language)\n",
    "        except sr.RequestError as e:\n",
    "            error_msg = f\"Voice recognition service error: {str(e)}\"\n",
    "            return self.translate(error_msg, \"en\", self.user_lang)\n",
    "        except sr.UnknownValueError:\n",
    "            error_msg = \"Could not understand audio.\"\n",
    "            return self.translate(error_msg, \"en\", self.user_lang)\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Voice input error: {str(e)}\"\n",
    "            return self.translate(error_msg, \"en\", self.user_lang)\n",
    "\n",
    "    def extract_condition_and_location(self, query: str) -> tuple:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        prompt = f\"\"\"\n",
    "        Extract the health condition and location from this query.\n",
    "        If no location is mentioned, return 'None' for location.\n",
    "        If no condition is mentioned, return 'None' for condition.\n",
    "        Respond with:\n",
    "        condition: [condition]\n",
    "        location: [location]\n",
    "        Query: \"{query}\"\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            text = response.text.strip()\n",
    "            condition_match = re.search(r'condition:\\s*(.+)', text)\n",
    "            location_match = re.search(r'location:\\s*(.+)', text)\n",
    "            condition = condition_match.group(1).strip() if condition_match else \"None\"\n",
    "            location = location_match.group(1).strip() if location_match else \"None\"\n",
    "            return condition, location\n",
    "        except Exception as e:\n",
    "            print(f\"Extraction error: {str(e)}\")\n",
    "            return \"None\", \"None\"\n",
    "\n",
    "    def process_query(self, query: str):\n",
    "        query_en = self.translate(query, self.user_lang, \"en\")\n",
    "        if query_en.lower() == \"clear history\":\n",
    "            self.memory.clear()\n",
    "            print(self.translate(\"Conversation history cleared.\", \"en\", self.user_lang))\n",
    "            return\n",
    "        self.memory.chat_memory.add_message(HumanMessage(content=query_en))\n",
    "        condition, location = self.extract_condition_and_location(query_en)\n",
    "        if condition.lower() != \"none\" and location.lower() != \"none\":\n",
    "            doctor_query = f\"{condition} near {location}\"\n",
    "            result_en = self.find_doctors(doctor_query)\n",
    "            result = self.translate(result_en, \"en\", self.user_lang)\n",
    "            print(f\"\\n{self.translate('Suggested Doctors:', 'en', self.user_lang)}\\n{result}\")\n",
    "            self.memory.chat_memory.add_message(AIMessage(content=result_en))\n",
    "        else:\n",
    "            prompt = f\"{SYSTEM_PROMPT}\\nChat History:\\n{self.memory.buffer}\\n\\nUser Query: {query_en}\"\n",
    "            response_en = self.llm._call(prompt)\n",
    "            response = self.translate(response_en, \"en\", self.user_lang)\n",
    "            print(f\"\\n{self.translate('Assistant:', 'en', self.user_lang)} {response}\")\n",
    "            self.memory.chat_memory.add_message(AIMessage(content=response_en))\n",
    "            for line in response_en.split('\\n'):\n",
    "                match = re.match(r\"Action:\\s*(\\w+)\\s*:\\s*(.+)\", line.strip())\n",
    "                if match:\n",
    "                    action, input_str = match.groups()\n",
    "                    if action in self.actions:\n",
    "                        result_en = self.actions[action](input_str.strip())\n",
    "                        result = self.translate(result_en, \"en\", self.user_lang)\n",
    "                        print(f\"\\n{self.translate('Action Result:', 'en', self.user_lang)} {result}\")\n",
    "                        self.memory.chat_memory.add_message(AIMessage(content=f\"Action {action} result: {result_en}\"))\n",
    "\n",
    "    def run(self):\n",
    "        print(\"=== Medical Assistant ===\")\n",
    "        print(\"Please specify your preferred language (e.g., English, Spanish, French).\")\n",
    "        lang_input = input(\"Language: \").strip()\n",
    "        prompt = f\"What is the ISO 639-1 code for the language '{lang_input}'?\"\n",
    "        try:\n",
    "            response = self.llm._call(prompt)\n",
    "            self.user_lang = response.strip().lower()\n",
    "            print(f\"Language set to {self.user_lang}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting language: {str(e)}. Defaulting to English.\")\n",
    "            self.user_lang = \"en\"\n",
    "\n",
    "        # Translate interface texts\n",
    "        interface_texts_en = {\n",
    "            \"options_menu\": \"Options: 1-Text, 2-Voice, 3-Image, q-Quit\",\n",
    "            \"select\": \"Select: \",\n",
    "            \"health_concern\": \"Your health concern: \",\n",
    "            \"image_path\": \"Image path: \",\n",
    "            \"goodbye\": \"Goodbye.\",\n",
    "            \"invalid_option\": \"Invalid option. Choose 1, 2, 3, or q.\",\n",
    "            \"clear_history_note\": \"Type 'clear history' during text input to reset the conversation.\"\n",
    "        }\n",
    "        self.interface_texts = {key: self.translate(text, \"en\", self.user_lang) for key, text in interface_texts_en.items()}\n",
    "\n",
    "        print(self.interface_texts[\"options_menu\"])\n",
    "        print(self.interface_texts[\"clear_history_note\"])\n",
    "\n",
    "        while True:\n",
    "            choice = input(self.interface_texts[\"select\"]).strip().lower()\n",
    "            if choice == \"1\":\n",
    "                query = input(self.interface_texts[\"health_concern\"]).strip()\n",
    "                if query:\n",
    "                    self.process_query(query)\n",
    "                else:\n",
    "                    print(self.translate(\"Please enter a valid query.\", \"en\", self.user_lang))\n",
    "            elif choice == \"2\":\n",
    "                print(self.translate(\"Initiating voice input...\", \"en\", self.user_lang))\n",
    "                query = self.get_voice_input()\n",
    "                if query and \"error\" not in query.lower():\n",
    "                    print(f\"{self.translate('Recognized:', 'en', self.user_lang)} {query}\")\n",
    "                    self.process_query(query)\n",
    "                else:\n",
    "                    print(query or self.translate(\"Voice input failed.\", \"en\", self.user_lang))\n",
    "            elif choice == \"3\":\n",
    "                path = input(self.interface_texts[\"image_path\"]).strip()\n",
    "                if path:\n",
    "                    print(self.translate(\"Analyzing medical image...\", \"en\", self.user_lang))\n",
    "                    result = self.analyze_medical_image(path)\n",
    "                    print(f\"\\n{self.translate('Analysis:', 'en', self.user_lang)} {result}\")\n",
    "                    self.memory.chat_memory.add_message(AIMessage(content=result))\n",
    "                else:\n",
    "                    print(self.translate(\"Please provide a valid image path.\", \"en\", self.user_lang))\n",
    "            elif choice == \"q\":\n",
    "                print(self.interface_texts[\"goodbye\"])\n",
    "                break\n",
    "            else:\n",
    "                print(self.interface_texts[\"invalid_option\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    assistant = MedicalAssistant()\n",
    "    assistant.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
